{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/githubofjay/FCC-MachineLearning-Course/blob/main/Copy_of_fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00929af-e392-4724-a901-f58cf3f76d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.25.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.62.0)\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "# try:\n",
        "#   # %tensorflow_version only exists in Colab.\n",
        "#   !pip install tf-nightly\n",
        "# except Exception:\n",
        "#   pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104491c6-08a4-449e-834b-e0cd0c7aa704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-27 15:46:29--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.3.33, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358233 (350K) [text/tab-separated-values]\n",
            "Saving to: ‘train-data.tsv’\n",
            "\n",
            "train-data.tsv      100%[===================>] 349.84K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-02-27 15:46:29 (50.3 MB/s) - ‘train-data.tsv’ saved [358233/358233]\n",
            "\n",
            "--2024-02-27 15:46:29--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.3.33, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118774 (116K) [text/tab-separated-values]\n",
            "Saving to: ‘valid-data.tsv’\n",
            "\n",
            "valid-data.tsv      100%[===================>] 115.99K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-02-27 15:46:29 (52.3 MB/s) - ‘valid-data.tsv’ saved [118774/118774]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g_h508FEClxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dde9ed8-f35d-4adc-c6cd-8e83c17b5583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_train = pd.read_csv(train_file_path, sep = \"\\t\", header = None, names = ['y', 'x'])\n",
        "df_test = pd.read_csv(test_file_path, sep = \"\\t\", header = None, names = ['y', 'x'])\n",
        "\n",
        "y_train = df_train['y'].astype('category').cat.codes\n",
        "y_test = df_test['y'].astype('category').cat.codes\n",
        "y_train[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515938d5-8bc9-4af8-e70a-c3290c8ba3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_eng = set(stopwords.words('english'))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_txt(txt):\n",
        "  txt = re.sub(r'([^\\s\\w])+', ' ', txt)\n",
        "  txt = txt.lower()\n",
        "  return txt\n",
        "\n",
        "X_train = df_train['x'].apply(lambda x : clean_txt(x))\n",
        "X_train[:5]"
      ],
      "metadata": {
        "id": "Y8BMXU-Y-8eE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a97a79-83cd-4fc5-e5ce-8b1c3b1d1be5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ahhhh just woken up had a bad dream about u th...\n",
              "1                             you can never do nothing\n",
              "2    now u sound like manky scouse boy steve like  ...\n",
              "3    mum say we wan to go then go  then she can shu...\n",
              "4    never y lei  i v lazy  got wat  dat day ü send...\n",
              "Name: x, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "#Keep top 1000 frequently occuring words\n",
        "max_words = 1000\n",
        "\n",
        "#Cut off the words after seeing 500 words in each document\n",
        "max_len = 500\n",
        "\n",
        "t = Tokenizer(num_words = max_words)\n",
        "t.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "kvZ11tH5_wcf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = t.texts_to_sequences(X_train)\n",
        "sequences[:5]\n",
        "\n",
        "seqs_matrix = sequence.pad_sequences(sequences, maxlen = max_len)\n",
        "seqs_matrix[:5]"
      ],
      "metadata": {
        "id": "F5pfjq9YAzJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d6e9ff-66b2-46db-9de1-617298ff8efa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,  47,  13,  12],\n",
              "       [  0,   0,   0, ..., 279,  31, 343],\n",
              "       [  0,   0,   0, ...,  43, 435, 531],\n",
              "       [  0,   0,   0, ...,  25, 344,  99],\n",
              "       [  0,   0,   0, ..., 200, 143,  79]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "i = tf.keras.layers.Input(shape=[max_len])\n",
        "x = tf.keras.layers.Embedding(max_words, 50)(i)\n",
        "x = tf.keras.layers.LSTM(64)(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1, activation='relu')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=i, outputs=x)\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='RMSprop',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "aIUibKmGBGh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e737e6-185e-4faf-fa34-8746341d668d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 500, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96337 (376.32 KB)\n",
            "Trainable params: 96337 (376.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(seqs_matrix, y_train,\n",
        "              batch_size=128, epochs=10,\n",
        "              validation_split=0.2,\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                  monitor='val_loss', min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unzMNPM4DS60",
        "outputId": "cf1df63a-b232-4f5f-a554-92f81fb1ba8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 36s 1s/step - loss: 0.3942 - accuracy: 0.8762 - val_loss: 0.1514 - val_accuracy: 0.9438\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 23s 848ms/step - loss: 0.1175 - accuracy: 0.9620 - val_loss: 0.1022 - val_accuracy: 0.9904\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 21s 784ms/step - loss: 0.0611 - accuracy: 0.9853 - val_loss: 0.0926 - val_accuracy: 0.9916\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 21s 794ms/step - loss: 0.0461 - accuracy: 0.9895 - val_loss: 0.0871 - val_accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 24s 884ms/step - loss: 0.0409 - accuracy: 0.9919 - val_loss: 0.1069 - val_accuracy: 0.9844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(X):\n",
        "  x = X.apply(lambda x:clean_txt(x))\n",
        "  x = t.texts_to_sequences(x)\n",
        "  return sequence.pad_sequences(x, maxlen = max_len)\n",
        "\n",
        "s = model.evaluate(preprocessing(df_test['x']), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3GaD6nhEDcK",
        "outputId": "4077a2d6-4b1f-43fc-98f3-32c90dc72dc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 3s 59ms/step - loss: 0.0594 - accuracy: 0.9842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J9tD9yACG6M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6af1ff-ea44-4a0a-ab9c-8c17cdab1ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 493ms/step\n",
            "(0.0, 'ham')\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  p = model.predict(preprocessing(pd.Series([pred_text])))[0]\n",
        "\n",
        "  return (p[0], (\"ham\" if p<0.5 else \"spam\"))\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dxotov85SjsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9becc45-8ae9-4a27-9abb-608f24e81ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}